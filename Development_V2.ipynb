{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012297dc-f1f7-425e-bc5f-667bf98db271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw LIMS dataset\n",
    "%run -i -n \"lims_export_v2.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57389c8-19c5-4965-b1dd-3ae218c65e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export LIMS and isolate relevant data ###\n",
    "df_lims = (\n",
    "    export_df_from_LIMS()\n",
    "    .pipe(isolate_relevant_data)\n",
    "    )\n",
    "### Oreder independant transformations ###\n",
    "df_lims = (\n",
    "    convert_numeric(df_lims)\n",
    "    .pipe(freetext_transform)\n",
    "    .pipe(convert_choice_fields)\n",
    "    .pipe(standardize_time_fields)\n",
    "    )\n",
    "### Critical convert long to wide ####\n",
    "df_lims = (\n",
    "    long_to_wide(df_lims)\n",
    "    .pipe(force_values)\n",
    "    .pipe(set_dtypes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f0c88-03be-4c6a-8b2a-905497832765",
   "metadata": {},
   "source": [
    "#### pipeline update progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f484f09-07c6-4325-ac99-a5c9aa470b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import raw LIMS dataset\n",
    "%run -i -n \"viral_lims_export.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c41d25-3b08-4672-b6b6-e0c27f6ab6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Export all lims data####\n",
    "df_lims = export_df_from_LIMS()\n",
    "\n",
    "### Critical convert long to wide ####\n",
    "df_lims = (\n",
    "    drop_null_sample_ID(df_lims)# #remove artifiact data from LIMS (missing sample ID's) \n",
    "    .pipe(drop_all_but_N1_N2)#Remove full rows where PCR Target is enything except N1 or N2\n",
    "    .pipe(below_lod_to_yes_no)\n",
    "    .pipe(long_to_wide) #meat and potatos! everything not under PCRTarget N1 or N2 will not be imported\n",
    "    )\n",
    "\n",
    "####Transform lims dataframe#### \n",
    "df_lims = (\n",
    "    rename_lims_columns(df_lims) \n",
    "    .pipe(verify_time_field) #remove from pipeline 04/12/2022\n",
    "    .pipe(convert_numeric) #convert numeric columns to floats, coerce errors\n",
    "    .pipe(freetext_transform)\n",
    "    .pipe(validate_yes_no_clms)\n",
    "    .pipe(validate_choice_fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a005348-35fb-4e7c-aa7c-5f2cfd1eae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lims.to_pickle(\"df_lims_origin.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7bf0fd-a95a-4bff-85b3-53eb3f07f7be",
   "metadata": {},
   "source": [
    "# Development - Validate that all fields are identical to V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bbc914-76c6-4971-ae1e-754ed93d63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lims_v2 = df_lims.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff68e23-9487-41f3-90cc-dd024e92406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lims_original = pd.read_pickle(\"df_lims_origin.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595c50c-b3c6-441c-8168-c95b3da4a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare shape\n",
    "print(df_lims_v2.shape)\n",
    "print(df_lims_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac09e28-e576-4679-9a92-c76b6843ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare columns\n",
    "print(set(df_lims_v2.columns) == set(df_lims_original.columns))\n",
    "\n",
    "#compare index\n",
    "print(set(df_lims_v2.index) == set(df_lims_original.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3699d-0a57-4ddc-8606-cfaa1fa609e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create datafrmae of Dtypes that are different between pipeline versions ###\n",
    "\n",
    "original_dtypes = df_lims_original.dtypes\n",
    "original_dtypes.name = \"original\"\n",
    "\n",
    "v2_dtypes = df_lims_v2.dtypes\n",
    "v2_dtypes.name = \"v2\"\n",
    "df_dtypes = pd.merge(original_dtypes, v2_dtypes, left_index=True, right_index = True)\n",
    "\n",
    "df_dtypes[df_dtypes[\"original\"] != df_dtypes[\"v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdfe470-6973-4d31-a90f-ef581bcc25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record 210042 is different due to this sample being analyzed twice - V2 code drops duplicates, keeps the last (by index not timestamp), V1 code keeps first by index #\n",
    "#special case: making n1_sars_cov2_below_lod unequal\n",
    "\n",
    "#record 210042 results in many unequal results\n",
    "df_lims_v2.drop(index = 210042, inplace = True)\n",
    "df_lims_original.drop(index = 210042, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c0a82-51df-4794-ad71-faa7d03105b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#06/14/2022, 220369 is another value that does not match between code version\n",
    "# need to verify the source, is this another duplicated sample?\n",
    "df_lims_v2.drop(index = 220369, inplace = True)\n",
    "df_lims_original.drop(index = 220369, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227472a4-5a91-4995-b4d4-00f42254463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#06/14/2022, 220381 is another value that does not match between code version\n",
    "# need to verify the source, is this another duplicated sample?\n",
    "df_lims_v2.drop(index = 220381, inplace = True)\n",
    "df_lims_original.drop(index = 220381, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13166b18-31e9-4e3e-af91-a3fd2ba49768",
   "metadata": {},
   "source": [
    "Columns are unequal due to dtype issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa65405-2223-405c-80bd-4aa17b4c8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rerun comparison process\n",
    "#compare all columns between the dataframes for equality\n",
    "\n",
    "for i in df_lims.columns:\n",
    "    \n",
    "    original = df_lims_original[i]\n",
    "    v2 = df_lims_v2[i]\n",
    "    \n",
    "    try:\n",
    "        pd.testing.assert_series_equal(original, v2, check_dtype=False)\n",
    "    except:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271f81f8-0254-4984-b69c-1dcb30130b01",
   "metadata": {},
   "source": [
    "#need to find source of difference in the following fields:\n",
    "\n",
    "\"pretreatment\" - resolved, error in original code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe16978-0994-46da-b7fa-339219e8d96d",
   "metadata": {},
   "source": [
    "# Scratch Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b7fa0-fd22-4b24-970c-827a067ae203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redcap\n",
    "#credentials for PID171\n",
    "token = \"AB21CE90EF475E08AC11F92105A39690\"\n",
    "url = 'https://redcap.doh.wa.gov/api/'\n",
    "\n",
    "#Create Project objects\n",
    "project = redcap.Project(url,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf5123-7c88-4de7-a1d6-a4a3681f3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_fields(project):\n",
    "    \"\"\"\n",
    "    create a summary dataframe to describe every standard field from default API export\n",
    "    \n",
    "    args:\n",
    "        pycap Project object\n",
    "    return:\n",
    "        Dataframe\n",
    "        \n",
    "    \"\"\"  \n",
    "    df_fields = project.export_field_names(format_type = \"df\")\n",
    "    df_meta = project.export_metadata(format_type = \"df\")\n",
    "    \n",
    "    #set aside choice fields Series\n",
    "    choice_fields = df_meta[df_meta[\"field_type\"].isin(['dropdown', 'radio', 'checkbox'])][\"select_choices_or_calculations\"].copy()#select field type \"dropdown\",\"radio\", \"checkbox\"\n",
    "    choice_fields = choice_fields[choice_fields.notnull()] #remove possibility of NA fields\n",
    "\n",
    "    #drop the first row, it is the index of dataframe export (unique identified: record_id, sample_id)\n",
    "    df_meta = df_meta.drop(df_meta.index[0])\n",
    "    df_fields = df_fields.drop(df_fields.index[0])\n",
    "\n",
    "    #only need 2 fields from metadata export\n",
    "    df_meta = df_meta[[\"form_name\", \"field_type\", \"text_validation_type_or_show_slider_number\"]].copy()\n",
    "\n",
    "    #combine fields from metadata and from export_field_names \n",
    "    df_fields_2 = df_fields.join(df_meta)\n",
    "    \n",
    "    #add field names that have type \"file\" (from metadata)\n",
    "    files_df = df_meta[df_meta[\"field_type\"] == \"file\"].copy()\n",
    "    files_df['export_field_name'] = files_df.index\n",
    "    df_fields_3 = pd.concat([df_fields_2, files_df])\n",
    "    \n",
    "    #set index to export_field_name\n",
    "    df_fields_3 = df_fields_3.set_index(\"export_field_name\")\n",
    "    \n",
    "    ##### add a new columns: str(dict) of possible choices for multiple choice fields####\n",
    "    fields_dict = {}\n",
    "    for i in choice_fields.iteritems():\n",
    "\n",
    "        string_to_process = i[1] #the value element of the series (as opposed to index element)\n",
    "        list_of_strings = string_to_process.split(\"|\") # split the string \n",
    "        keys_values_list = [i.split(\", \", 1) for i in list_of_strings]# split each list once for list of lists [key, values]\n",
    "        values_dict = {t[0]:t[1] for t in keys_values_list} #dictionary of key value pairs\n",
    "        fields_dict[i[0]] =  str(values_dict)\n",
    "\n",
    "    choice_fields_series = pd.Series(fields_dict)\n",
    "\n",
    "    complete = pd.concat([df_fields_3 ,choice_fields_series.to_frame(\"Choice Values\")], axis = 1)\n",
    "    \n",
    "    ## add special case for multiple choice fields - \"yesno\" field type \n",
    "    yesno_dict = {\"1\":\"Yes\", \"0\":\"No\"}\n",
    "    yesno_index = df_meta[df_meta[\"field_type\"] == \"yesno\"].index\n",
    "    yesno_series = pd.Series(str(yesno_dict), yesno_index) #create series, yes/values and index for all yesno field type\n",
    "    yesno_frame = yesno_series.to_frame(\"Choice Values\")\n",
    "    \n",
    "    df_joined = complete.join(yesno_frame, lsuffix='_l', rsuffix='_r')\n",
    "    \n",
    "    complete[\"Choice Values\"] = df_joined[\"Choice Values_l\"].fillna(df_joined[\"Choice Values_r\"])\n",
    "    \n",
    "    return complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491234c0-c28a-4e34-ad46-b88bb6524c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = describe_fields(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60d50a-02f5-4cee-b468-8e2ebd60aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"sample_collect_time\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6fa75-caf2-4c82-9b9c-92886f91a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_validation_type_or_show_slider_number\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5eaf31-4b17-4ed0-abb2-55ea0ebdc4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transform22] *",
   "language": "python",
   "name": "conda-env-transform22-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
